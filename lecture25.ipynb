{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "919addca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.vectorstores import Neo4jVector\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.graphs import Neo4jGraph\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain.chains.graph_qa.cypher import GraphCypherQAChain\n",
    "import streamlit as st\n",
    "import tempfile\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b9d8b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e77283e",
   "metadata": {},
   "outputs": [],
   "source": [
    "neo4j_uri = os.getenv(\"NEO4J_URI\")\n",
    "neo4j_username = os.getenv(\"NEO4J_USERNAME\")\n",
    "neo4j_password = os.getenv(\"NEO4J_PASSWORD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d939c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Neo4jGraph(url=neo4j_uri, username=neo4j_username, password=neo4j_password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63226b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Neo4jGraph(url=NEO4J_URI, username=NEO4J_USERNAME, password=NEO4J_PASSWORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e181d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fa91cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "llm = ChatAnthropic(model=\"claude-3-5-haiku-20241022\", temperature=0.1, max_retries=2, max_tokens=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20f7045f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How are you doing today? Is there anything I can help you with?', additional_kwargs={}, response_metadata={'id': 'msg_017rSgBqY6EafxRYPpfiRPXK', 'model': 'claude-3-5-haiku-20241022', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 8, 'output_tokens': 20, 'server_tool_use': None, 'service_tier': 'standard', 'cache_creation': {'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}}, 'model_name': 'claude-3-5-haiku-20241022'}, id='run--58c4a38c-5f3e-4d0c-be77-aed8ca25b2a5-0', usage_metadata={'input_tokens': 8, 'output_tokens': 20, 'total_tokens': 28, 'input_token_details': {'cache_read': 0, 'cache_creation': 0, 'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ece0482",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\", \n",
    "        \"You are helpful assistant that translates ENglish to Urdu. Translate the user sentence.\"\n",
    "    ),\n",
    "    (\"human\", \"I love programming\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b7b2117",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_msg = llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c93e445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='میں پروگرامنگ سے محبت کرتا ہوں۔', additional_kwargs={}, response_metadata={'id': 'msg_01E8kS96KbGrZYE78u4Fmiym', 'model': 'claude-3-5-haiku-20241022', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 31, 'output_tokens': 28, 'server_tool_use': None, 'service_tier': 'standard', 'cache_creation': {'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}}, 'model_name': 'claude-3-5-haiku-20241022'}, id='run--d0d7767a-78bc-426f-a3aa-1706d3b05266-0', usage_metadata={'input_tokens': 31, 'output_tokens': 28, 'total_tokens': 59, 'input_token_details': {'cache_read': 0, 'cache_creation': 0, 'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5ccc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "[\n",
    "    (\n",
    "        \"system\", \n",
    "        \"You are helpful assistant that translates {input_language} to {output_language}. Translate the user sentence.\"\n",
    "    ),\n",
    "    (\"human\", \"{input}\")\n",
    "]\n",
    ")\n",
    "\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8030ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"input_language\": \"English\", \"output_language\": \"Urdu\", \"input\": \"The capital of Pakistan is Islamabad\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67893235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'پاکستان کا دارالحکومت اسلام آباد ہے۔'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "400ac4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class GetWeather(BaseModel):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    \n",
    "    location: str = Field(default=\"\", description=\"The city and state, e.g Karachi, Islamabad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "616c8e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools([GetWeather])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2c078e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_msg = llm_with_tools.invoke(\"Which city is hotter today Karachi or Islamabad?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e04f9f89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=[{'text': \"I'll help you compare the temperatures of Karachi and Islamabad by checking their current weather. I'll retrieve the weather information for both cities.\", 'type': 'text'}, {'id': 'toolu_01NYuFhRotgReEjpM2UwAjoA', 'input': {'location': 'Karachi, Pakistan'}, 'name': 'GetWeather', 'type': 'tool_use'}, {'id': 'toolu_01MmuvUg2HPHXaD1DTmPUtxy', 'input': {'location': 'Islamabad, Pakistan'}, 'name': 'GetWeather', 'type': 'tool_use'}], additional_kwargs={}, response_metadata={'id': 'msg_01Uzn5fP47GwngTzxDqk3dEp', 'model': 'claude-3-5-haiku-20241022', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 359, 'output_tokens': 129, 'server_tool_use': None, 'service_tier': 'standard', 'cache_creation': {'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}}, 'model_name': 'claude-3-5-haiku-20241022'}, id='run--4a57f629-7a0c-497e-b57a-8697daa0ccb5-0', tool_calls=[{'name': 'GetWeather', 'args': {'location': 'Karachi, Pakistan'}, 'id': 'toolu_01NYuFhRotgReEjpM2UwAjoA', 'type': 'tool_call'}, {'name': 'GetWeather', 'args': {'location': 'Islamabad, Pakistan'}, 'id': 'toolu_01MmuvUg2HPHXaD1DTmPUtxy', 'type': 'tool_call'}], usage_metadata={'input_tokens': 359, 'output_tokens': 129, 'total_tokens': 488, 'input_token_details': {'cache_read': 0, 'cache_creation': 0, 'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a6999e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "\n",
    "client = anthropic.Anthropic()\n",
    "file = client.beta.files.upload(file=open(\"test_image.jpg\", \"rb\"))\n",
    "\n",
    "image_file_id = file.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba0e6151",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "llm = ChatAnthropic(model=\"claude-3-5-haiku-20241022\", betas=[\"files-api-2025-04-14\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e74ea04",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_message = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"Describe this image\",\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"image\",\n",
    "            \"source\": {\n",
    "                \"type\":\"file\",\n",
    "                \"file_id\": image_file_id\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d738c726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='This image captures a dramatic wildlife scene on the African savanna. A hyena is confronting or challenging a gazelle or antelope, while a cheetah is running in the background, apparently in pursuit. The scene illustrates the intense predator-prey dynamics of the grassland ecosystem.\\n\\nThe hyena appears to be in a threatening posture, with its body low and confrontational. The antelope seems to be mid-leap, trying to escape the potential danger. The cheetah, known for its incredible speed, is running in the background, adding another layer of tension to the scene.\\n\\nThe landscape is a typical savanna setting, with a grassy, slightly brownish-green terrain. The animals are positioned in a way that creates a sense of motion and imminent action, showcasing the constant struggle for survival in the wild.\\n\\nThis image provides a raw, unfiltered look at the harsh realities of life in the African wilderness, where predators and prey are constantly engaged in a life-or-death dance.', additional_kwargs={}, response_metadata={'id': 'msg_0181TkC1wrNDTyak5qwK8xFa', 'container': None, 'model': 'claude-3-5-haiku-20241022', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation': {'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 62, 'output_tokens': 218, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-3-5-haiku-20241022'}, id='run--fd8e70a7-da6f-4cd7-a7e4-b221cffcb3f1-0', usage_metadata={'input_tokens': 62, 'output_tokens': 218, 'total_tokens': 280, 'input_token_details': {'cache_read': 0, 'cache_creation': 0, 'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke([input_message])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
