{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a28a6f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Repos\\Projects\\Analytix Camp GenAI\\Analytix-Camp-GenAI\\analytix_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Repos\\Projects\\Analytix Camp GenAI\\Analytix-Camp-GenAI\\analytix_env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Repos\\Projects\\Analytix Camp GenAI\\Analytix-Camp-GenAI\\analytix_env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (625 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "from langchain_docling import DoclingLoader\n",
    "\n",
    "FILE_PATH = \"Docs/plan_and_solve.pdf\"\n",
    "\n",
    "loader = DoclingLoader(file_path=FILE_PATH)\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b599c0df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models\\nLei Wang 1 Wanyu Xu 2 Yihuai Lan Zhiqiang Hu 3 Yunshi Lan 4 3 1 ∗\\nRoy Ka-Wei Lee Ee-Peng Lim\\n1\\n3 Singapore University of Technology and Design\\nSingapore Management University 2 Southwest Jiaotong University 4 East China Normal University'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6eb13db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "doc_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=0)\n",
    "splitted_docs = doc_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93d4c051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'Docs/plan_and_solve.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/2', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 1, 'bbox': {'l': 133.092, 't': 729.5000146484375, 'r': 473.642, 'b': 708.5860146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 65]}]}, {'self_ref': '#/texts/3', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 1, 'bbox': {'l': 217.541, 't': 714.0190146484375, 'r': 381.97, 'b': 703.2710146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 26]}]}, {'self_ref': '#/texts/4', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 1, 'bbox': {'l': 213.362, 't': 701.6050146484375, 'r': 217.597, 'b': 694.6390146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1]}]}, {'self_ref': '#/texts/5', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 1, 'bbox': {'l': 181.405, 't': 673.7090146484375, 'r': 416.861, 'b': 661.4480146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 47]}]}, {'self_ref': '#/texts/6', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 1, 'bbox': {'l': 218.094, 't': 699.6050146484375, 'r': 384.905, 'b': 647.5000146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 94]}]}], 'headings': ['Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 13445272788269711108, 'filename': 'plan_and_solve.pdf'}}}, page_content='Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models'),\n",
       " Document(metadata={'source': 'Docs/plan_and_solve.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/2', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 1, 'bbox': {'l': 133.092, 't': 729.5000146484375, 'r': 473.642, 'b': 708.5860146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 65]}]}, {'self_ref': '#/texts/3', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 1, 'bbox': {'l': 217.541, 't': 714.0190146484375, 'r': 381.97, 'b': 703.2710146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 26]}]}, {'self_ref': '#/texts/4', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 1, 'bbox': {'l': 213.362, 't': 701.6050146484375, 'r': 217.597, 'b': 694.6390146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1]}]}, {'self_ref': '#/texts/5', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 1, 'bbox': {'l': 181.405, 't': 673.7090146484375, 'r': 416.861, 'b': 661.4480146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 47]}]}, {'self_ref': '#/texts/6', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 1, 'bbox': {'l': 218.094, 't': 699.6050146484375, 'r': 384.905, 'b': 647.5000146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 94]}]}], 'headings': ['Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 13445272788269711108, 'filename': 'plan_and_solve.pdf'}}}, page_content='Lei Wang 1 Wanyu Xu 2 Yihuai Lan Zhiqiang Hu 3 Yunshi Lan 4 3 1 ∗\\nRoy Ka-Wei Lee Ee-Peng Lim\\n1'),\n",
       " Document(metadata={'source': 'Docs/plan_and_solve.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/2', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 1, 'bbox': {'l': 133.092, 't': 729.5000146484375, 'r': 473.642, 'b': 708.5860146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 65]}]}, {'self_ref': '#/texts/3', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 1, 'bbox': {'l': 217.541, 't': 714.0190146484375, 'r': 381.97, 'b': 703.2710146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 26]}]}, {'self_ref': '#/texts/4', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 1, 'bbox': {'l': 213.362, 't': 701.6050146484375, 'r': 217.597, 'b': 694.6390146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1]}]}, {'self_ref': '#/texts/5', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 1, 'bbox': {'l': 181.405, 't': 673.7090146484375, 'r': 416.861, 'b': 661.4480146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 47]}]}, {'self_ref': '#/texts/6', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 1, 'bbox': {'l': 218.094, 't': 699.6050146484375, 'r': 384.905, 'b': 647.5000146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 94]}]}], 'headings': ['Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 13445272788269711108, 'filename': 'plan_and_solve.pdf'}}}, page_content='3 Singapore University of Technology and Design'),\n",
       " Document(metadata={'source': 'Docs/plan_and_solve.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/2', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 1, 'bbox': {'l': 133.092, 't': 729.5000146484375, 'r': 473.642, 'b': 708.5860146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 65]}]}, {'self_ref': '#/texts/3', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 1, 'bbox': {'l': 217.541, 't': 714.0190146484375, 'r': 381.97, 'b': 703.2710146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 26]}]}, {'self_ref': '#/texts/4', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 1, 'bbox': {'l': 213.362, 't': 701.6050146484375, 'r': 217.597, 'b': 694.6390146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1]}]}, {'self_ref': '#/texts/5', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 1, 'bbox': {'l': 181.405, 't': 673.7090146484375, 'r': 416.861, 'b': 661.4480146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 47]}]}, {'self_ref': '#/texts/6', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 1, 'bbox': {'l': 218.094, 't': 699.6050146484375, 'r': 384.905, 'b': 647.5000146484375, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 94]}]}], 'headings': ['Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 13445272788269711108, 'filename': 'plan_and_solve.pdf'}}}, page_content='Singapore Management University 2 Southwest Jiaotong University 4 East China Normal University'),\n",
       " Document(metadata={'source': 'Docs/plan_and_solve.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/8', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 1, 'bbox': {'l': 87.565, 't': 602.2900146484375, 'r': 273.866, 'b': 187.26301464843755, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1561]}]}], 'headings': ['Abstract'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 13445272788269711108, 'filename': 'plan_and_solve.pdf'}}}, page_content='Abstract'),\n",
       " Document(metadata={'source': 'Docs/plan_and_solve.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/8', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 1, 'bbox': {'l': 87.565, 't': 602.2900146484375, 'r': 273.866, 'b': 187.26301464843755, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1561]}]}], 'headings': ['Abstract'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 13445272788269711108, 'filename': 'plan_and_solve.pdf'}}}, page_content='Large language models (LLMs) have recently been shown to deliver impressive performance in various'),\n",
       " Document(metadata={'source': 'Docs/plan_and_solve.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/8', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 1, 'bbox': {'l': 87.565, 't': 602.2900146484375, 'r': 273.866, 'b': 187.26301464843755, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1561]}]}], 'headings': ['Abstract'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 13445272788269711108, 'filename': 'plan_and_solve.pdf'}}}, page_content='NLP tasks. To tackle multi-step reasoning tasks, few-shot chain-of-thought (CoT) prompting includes'),\n",
       " Document(metadata={'source': 'Docs/plan_and_solve.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/8', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 1, 'bbox': {'l': 87.565, 't': 602.2900146484375, 'r': 273.866, 'b': 187.26301464843755, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1561]}]}], 'headings': ['Abstract'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 13445272788269711108, 'filename': 'plan_and_solve.pdf'}}}, page_content='a few manually crafted step-by-step reasoning demonstrations which enable LLMs to explicitly'),\n",
       " Document(metadata={'source': 'Docs/plan_and_solve.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/8', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 1, 'bbox': {'l': 87.565, 't': 602.2900146484375, 'r': 273.866, 'b': 187.26301464843755, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1561]}]}], 'headings': ['Abstract'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 13445272788269711108, 'filename': 'plan_and_solve.pdf'}}}, page_content='generate reasoning steps and improve their reasoning task accuracy. To eliminate the manual effort,'),\n",
       " Document(metadata={'source': 'Docs/plan_and_solve.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/8', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 1, 'bbox': {'l': 87.565, 't': 602.2900146484375, 'r': 273.866, 'b': 187.26301464843755, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 1561]}]}], 'headings': ['Abstract'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 13445272788269711108, 'filename': 'plan_and_solve.pdf'}}}, page_content=\"Zeroshot-CoT concatenates the target problem statement with ' Let's think step by step ' as an\")]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitted_docs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06790daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"meta-llama-3.1-8b-instruct\",\n",
    "    base_url=\"http://127.0.0.1:1234/v1\",\n",
    "    api_key=\"lm-studio\",\n",
    "    temperature=0.7,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd9775f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "You are an expert document summarizer with experience in extracting key informations and insights from various types of documents\n",
    "\n",
    "Document for Analysis:\n",
    "{doc}\n",
    "\"\"\"\n",
    "\n",
    "summary_prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2785af8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_chain = summary_prompt | llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbf2527",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = summary_chain.invoke(splitted_docs[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "519c2f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**Document Summary**\\n\\nThe document is a PDF file titled \"Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models\". The document appears to be an academic paper, likely from the field of Natural Language Processing (NLP).\\n\\n**Key Findings and Insights**\\n\\n1. **Large Language Models**: The authors mention that large language models (LLMs) have recently shown impressive performance in various NLP tasks.\\n2. **Multi-Step Reasoning Tasks**: To tackle multi-step reasoning tasks, the authors propose a technique called few-shot chain-of-thought (CoT) prompting, which includes manually crafted step-by-step reasoning demonstrations to enable LLMs to explicitly reason about complex problems.\\n3. **Plan-and-Solve Prompting**: The paper introduces plan-and-solve prompting as an approach to improve zero-shot CoT reasoning in LLMs.\\n4. **Contributors and Affiliations**: The contributors listed include Lei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu, Yunshi Lan, Roy Ka-Wei Lee, and Ee-Peng Lim from various institutions such as Singapore University of Technology and Design, Singapore Management University, Southwest Jiaotong University, and East China Normal University.\\n\\n**Abstract**\\n\\nThe abstract provides a brief overview of the paper\\'s main contributions. It highlights that LLMs have achieved impressive performance in NLP tasks but struggle with multi-step reasoning tasks. To address this limitation, the authors propose few-shot CoT prompting as an effective technique to enable LLMs to reason about complex problems.\\n\\n**Possible Research Questions or Hypotheses**\\n\\n1. Can plan-and-solve prompting improve zero-shot chain-of-thought reasoning in LLMs?\\n2. How does few-shot CoT prompting compare to other techniques for tackling multi-step reasoning tasks?\\n3. What are the limitations of current LLM architectures that hinder their ability to reason about complex problems?'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analytix_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
